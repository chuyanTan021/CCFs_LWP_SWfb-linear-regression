{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a217701-f2e9-4daa-94de-96ed36518e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "from scipy.stats import *\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "# self_defined modules\n",
    "from area_mean import *\n",
    "from binned_cyFunctions5 import *\n",
    "from read_hs_file import read_var_mod\n",
    "from read_var_obs import *\n",
    "\n",
    "from calc_LRM_metric import *\n",
    "from get_LWPCMIP5data import *\n",
    "from get_LWPCMIP6data import *\n",
    "from get_OBSLRMdata import *\n",
    "from fitLRM_cy1 import *\n",
    "from fitLRM_cy2 import *\n",
    "# from fitLRM_cy4 import *\n",
    "from useful_func_cy import *\n",
    "from calc_Radiation_LRM_1 import *\n",
    "from calc_Radiation_LRM_2 import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5fb1cd-2e4c-42a0-a6d2-751bbb44e664",
   "metadata": {},
   "source": [
    "# calc_LRMobs_metric, fitLRMobs(fitLRM_1, 2, 4)\n",
    "# & Aploting_Sep11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ef3be3-a63c-405d-9c5e-2ffed8b9416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calc_LRMobs_metric import *\n",
    "from fitLRMobs import *\n",
    "from Aploting_Sep11 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8740b3-78b1-45fa-9b03-05c705fa27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_range1=[2013, 1, 15]\n",
    "valid_range2=[2016, 12, 31]\n",
    "valid_range3=[2003, 1, 15]\n",
    "valid_range4=[2012, 12, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1f030a-666c-46c4-a274-8262cc0633b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-7837f7ddc117>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-7837f7ddc117>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    LWP_obs_trends(predict_result_1r['LWP_actual_predict'], predict_result_1r['LWP_predi_predict'], predict_result_1r['LWP_actual_training'], predict_result_1r['LWP_predi_training'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 1r\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# 'valid_range1' and 'valid_range2' give the time stamps of starting and ending times of data for training,\n",
    "# 'valid_range3' and 'valid_range4' give the time stamps of starting and ending times of data for predicting.\n",
    "# 'THRESHOLD_sst' is the cut-off of 'Sea surface temperature' for partitioning the 'Hot'/'Cold' LRM regimes;\n",
    "# 'THRESHOLD_sub' is the cut-off of '500 mb Vertical Velocity (Pressure)' for partitioning 'Up'/'Down' regimes.\n",
    "# ..\n",
    "# ------------------\n",
    "# Southern Ocean 5 * 5 degree bin box\n",
    "# Using to do area_mean\n",
    "s_range = arange(-90., 90., 5.) + 2.5  #..global-region latitude edge: (36)\n",
    "x_range = arange(-180., 180., 5.)  #..logitude sequences edge: number: 72\n",
    "y_range = arange(-85, -40., 5.) + 2.5  #..southern-ocaen latitude edge: 9\n",
    "\n",
    "\n",
    "# Function #1 loopping through variables space to find the cut-offs of LRM (Multi-Linear Regression Model).\n",
    "dict_training, lats_Array, lons_Array, times_Array_training = Pre_processing(s_range, x_range, y_range, valid_range1 = valid_range1, valid_range2 = valid_range2)\n",
    "\n",
    "dict_predict, lats_Array, lons_Array, times_Array_predict = Pre_processing(s_range, x_range, y_range, valid_range1 = valid_range3, valid_range2 = valid_range4)\n",
    "\n",
    "# Loop_OBS_LRM(dict_training, dict_predict, s_range, x_range, y_range)\n",
    "\n",
    "    \n",
    "# Function #2 training LRM with using no cut-off, then use it to predict another historical period.\n",
    "predict_result_1r = fitLRMobs_1(dict_training, dict_predict, s_range, y_range, x_range, lats_Array, lons_Array)\n",
    "std_dev_LWP = predict_result_1r['std_LWP_training']\n",
    "# plotting and correlation to the actual value of predict period's LWP:\n",
    "\n",
    "# monthly, binned\n",
    "\n",
    "LWP_obs_trends(predict_result_1r['LWP_actual_predict'], predict_result_1r['LWP_predi_predict'], predict_result_1r['LWP_actual_training'], predict_result_1r['LWP_predi_training'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 2)\n",
    "\n",
    "print(pearsonr(area_mean(predict_result_1r['LWP_actual_predict']* std_dev_LWP, y_range, x_range), area_mean(predict_result_1r['LWP_predi_predict']* std_dev_LWP, y_range, x_range)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec49775-c4a7-4c4a-96ea-54be6b5af352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut-off folder ['/glade/scratch/chuyan/obs_output/OBS__STAT_pi+abr_22x_31y_Sep11th.npz']\n",
      "TR_min_abs(bias):  284.5258187711201   K  -0.014617270429645265  Pa/s \n",
      "TR_large_pi_R_2:  283.9439510076129   K  0.004837945345928386  Pa/s \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fitLRMobs_2_updown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6e218e507d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TR_large_pi_R_2: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sst2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'  K '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sub2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m' Pa/s '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredict_result_2r_updown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitLRMobs_2_updown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sst2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sub2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlats_Array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons_Array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpredict_result_2r_hotcold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitLRMobs_2_hotcold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sst2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_sub2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlats_Array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlons_Array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fitLRMobs_2_updown' is not defined"
     ]
    }
   ],
   "source": [
    "# Function #3,4,5 training LRM with cut_off (TR_sst &/or TR_sub)\n",
    "\n",
    "WD = '/glade/scratch/chuyan/obs_output/'\n",
    "folder = glob.glob(WD + 'OBS__' + 'STAT_pi+abr_'+'22x_31y_Sep11th'+ '.npz')\n",
    "print('cut-off folder', folder)\n",
    "\n",
    "output_ARRAY = np.load(folder[0], allow_pickle=True)  # str(TR_sst)\n",
    "\n",
    "TR_sst1 = output_ARRAY['TR_minabias_SST']\n",
    "TR_sub1 = output_ARRAY['TR_minabias_SUB']\n",
    "TR_sst2 = output_ARRAY['TR_maxR2_SST']\n",
    "TR_sub2 = output_ARRAY['TR_maxR2_SUB']\n",
    "\n",
    "print(\"TR_min_abs(bias): \" , TR_sst1, '  K ', TR_sub1 , ' Pa/s ')\n",
    "print(\"TR_large_pi_R_2: \", TR_sst2, '  K ', TR_sub2 , ' Pa/s ')\n",
    "\n",
    "predict_result_2r_updown = fitLRMobs_2_updown(dict_training, dict_predict, TR_sst2, TR_sub2, s_range, y_range, x_range, lats_Array, lons_Array)\n",
    "\n",
    "predict_result_2r_hotcold = fitLRMobs_2_hotcold(dict_training, dict_predict, TR_sst2, TR_sub2, s_range, y_range, x_range, lats_Array, lons_Array)\n",
    "\n",
    "predict_result_4r = fitLRMobs_4(dict_training, dict_predict, TR_sst2, TR_sub2, s_range, y_range, x_range, lats_Array, lons_Array)\n",
    "\n",
    "# Plotting for the 'Liquid Water Path' trends in the historical period\n",
    "LWP_obs_trends(predict_result_2r_updown['LWP_actual_predict'], predict_result_2r_updown['LWP_predi_predict'], predict_result_2r_updown['LWP_actual_training'], predict_result_2r_updown['LWP_predi_training'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 2)\n",
    "\n",
    "LWP_obs_trends(predict_result_2r_hotcold['LWP_actual_predict'], predict_result_2r_hotcold['LWP_predi_predict'], predict_result_2r_hotcold['LWP_actual_training'], predict_result_2r_hotcold['LWP_predi_training'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 2)\n",
    "\n",
    "LWP_obs_trends(predict_result_4r['LWP_actual_predict'], predict_result_4r['LWP_predi_predict'], predict_result_4r['LWP_actual_training'], predict_result_4r['LWP_predi_training'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 2)\n",
    "print(pearsonr(area_mean(annually_mean(predict_result_4r['LWP_actual_predict'], times_Array_predict, label = 'mon'), y_range, x_range), area_mean(annually_mean(predict_result_4r['LWP_predi_predict'], times_Array_predict, label = 'mon'), y_range, x_range)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e15d4b-7bbf-4dcd-8871-cd3154fae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCF trends in historical period:\n",
    "\n",
    "LWP_obs_trends_2(dict_predict['p_e'], dict_predict['p_e'], times_Array_predict, y_range, x_range, data_type = '1', running_mean_window = 2)\n",
    "\n",
    "LWP_obs_trends(dict_predict['SUB'], dict_predict['SUB'], dict_training['SUB'], dict_training['SUB'], times_Array_predict, times_Array_training, y_range, x_range, data_type = '3', running_mean_window = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42feadd7-ba92-4722-994d-9273136bc07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ceb2d3c-6380-4905-9b51-2442d41becad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# loop_small_LRM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d55fe2-b007-4888-afd3-ea31fe56a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 'piControl'\n",
    "\n",
    "# CMIP6: 31 (30: BCCCSMCM2MR)\n",
    "AWICM11MR = {'modn': 'AWI-CM-1-1-MR', 'consort': 'AWI', 'cmip': 'cmip6',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "BCCCSMCM2MR = {'modn': 'BCC-CSM2-MR', 'consort': 'BCC', 'cmip': 'cmip6',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "BCCESM1 = {'modn': 'BCC-ESM1', 'consort': 'BCC', 'cmip': 'cmip6',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CAMSCSM1 = {'modn': 'CAMS-CSM1-0', 'consort': 'CAMS', 'cmip': 'cmip6',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CMCCCM2SR5 = {'modn': 'CMCC-CM2-SR5', 'consort': 'CMCC', 'cmip': 'cmip6', \n",
    "             'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CESM2 = {'modn': 'CESM2', 'consort': 'NCAR', 'cmip': 'cmip6',\n",
    "             'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CESM2FV2 = {'modn': 'CESM2-FV2', 'consort': 'NCAR', 'cmip': 'cmip6',\n",
    "             'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CESM2WACCM = {'modn': 'CESM2-WACCM', 'consort': 'NCAR', 'cmip': 'cmip6',\n",
    "             'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "CESM2WACCMFV2 = {'modn': 'CESM2-WACCM-FV2', 'consort': 'NCAR', 'cmip': 'cmip6',\n",
    "             'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "\n",
    "CNRMCM61 = {'modn': 'CNRM-CM6-1', 'consort': 'CNRM-CERFACS', 'cmip': 'cmip6', \n",
    "               'exper': exp, 'ensmem': 'r1i1p1f2', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "CNRMCM61HR = {'modn': 'CNRM-CM6-1-HR', 'consort': 'CNRM-CERFACS', 'cmip': 'cmip6',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1f2', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "CNRMESM21 = {'modn': 'CNRM-ESM2-1', 'consort': 'CNRM-CERFACS', 'cmip': 'cmip6', \n",
    "                 'exper': exp, 'ensmem': 'r1i1p1f2', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "CanESM5 = {'modn': 'CanESM5', 'consort': 'CCCma', 'cmip': 'cmip6',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "E3SM10 = {'modn': 'E3SM-1-0', 'consort': 'E3SM-Project', 'cmip': 'cmip6',\n",
    "              'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "\n",
    "ECEarth3 = {'modn': 'EC-Earth3', 'consort': 'EC-Earth-Consortium', 'cmip': 'cmip6',\n",
    "       'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "ECEarth3Veg = {'modn': 'EC-Earth3-Veg', 'consort': 'EC-Earth-Consortium', 'cmip': 'cmip6',\n",
    "       'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "\n",
    "FGOALSg3 = {'modn': 'FGOALS-g3', 'consort': 'CAS', 'cmip': 'cmip6',\n",
    "                'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "GISSE21G = {'modn': 'GISS-E2-1-G', 'consort': 'NASA-GISS', 'cmip': 'cmip6',\n",
    "                'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "GISSE21H = {'modn': 'GISS-E2-1-H', 'consort': 'NASA-GISS', 'cmip': 'cmip6',\n",
    "                'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "GISSE22G = {'modn': 'GISS-E2-2-G', 'consort': 'NASA-GISS', 'cmip': 'cmip6',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "GFDLCM4 = {'modn': 'GFDL-CM4', 'consort': 'NOAA-GFDL', 'cmip': 'cmip6',\n",
    "           'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr1', \"typevar\": 'Amon'}\n",
    "# HADGEM3 = {'modn': 'HadGEM3-GC31-LL', 'consort': 'MOHC', 'cmip': 'cmip6',\n",
    "#             'exper': 'piControl', 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}   #..missing 'wap' in 'piControl' exp(Daniel says that HadGEM3-GC31 not using p-level, so doesn't have variables on p-level\n",
    "INM_CM48 = {'modn': 'INM-CM4-8', 'consort': 'INM', 'cmip': 'cmip6', \n",
    "                'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr1', \"typevar\": 'Amon'}\n",
    "IPSLCM6ALR = {'modn': 'IPSL-CM6A-LR', 'consort': 'IPSL', 'cmip': 'cmip6',\n",
    "                  'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gr', \"typevar\": 'Amon'}\n",
    "MIROCES2L = {'modn': 'MIROC-ES2L', 'consort': 'MIROC', 'cmip': 'cmip6',\n",
    "              'exper': exp, 'ensmem': 'r1i1p1f2', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "MIROC6 = {'modn': 'MIROC6', 'consort': 'MIROC', 'cmip': 'cmip6',\n",
    "              'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "MPIESM12LR = {'modn': 'MPI-ESM1-2-LR', 'consort': 'MPI-M', 'cmip': 'cmip6',\n",
    "                  'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "MRIESM20 = {'modn': 'MRI-ESM2-0', 'consort': 'MRI', 'cmip': 'cmip6',\n",
    "                'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "NESM3 = {'modn': 'NESM3', 'consort': 'NUIST', 'cmip': 'cmip6', \n",
    "                 'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "NorESM2MM = {'modn': 'NorESM2-MM', 'consort': 'NCC', 'cmip': 'cmip6',\n",
    "                 'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "SAM0 = {'modn': 'SAM0-UNICON', 'consort': 'SNU', 'cmip': 'cmip6', \n",
    "            'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "TaiESM1 = {'modn': 'TaiESM1', 'consort': 'AS-RCEC', 'cmip': 'cmip6', \n",
    "                 'exper': exp, 'ensmem': 'r1i1p1f1', 'gg': 'gn', \"typevar\": 'Amon'}\n",
    "\n",
    "# CMIP5: 20 (18, ACCESS10, ACCESS13)\n",
    "ACCESS10 = {'modn': 'ACCESS1-0', 'consort': 'CSIRO-BOM', 'cmip': 'cmip5',   # 2-d (145) and 3-d (146) variables have different lat shape\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "ACCESS13 = {'modn': 'ACCESS1-3', 'consort': 'CSIRO-BOM', 'cmip': 'cmip5',   # 2-d (145) and 3-d (146) variables have different lat shape\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "BNUESM = {'modn': 'BNU-ESM', 'consort': 'BNU', 'cmip': 'cmip5',\n",
    "          'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "\n",
    "CCSM4 = {'modn': 'CCSM4', 'consort': 'NCAR', 'cmip': 'cmip5',\n",
    "             'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "CNRMCM5 = {'modn': 'CNRM-CM5', 'consort': 'CNRM-CERFACS', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "CSIRO_Mk360 = {'modn': 'CSIRO-Mk3-6-0', 'consort': 'CSIRO-QCCCE', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "CanESM2 = {'modn': 'CanESM2', 'consort': 'CCCma', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "FGOALSg2 = {'modn': 'FGOALS-g2', 'consort': 'LASG-CESS', 'cmip': 'cmip5',   # missing 'prw' in piControl\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "FGOALSs2 = {'modn': 'FGOALS-s2', 'consort': 'LASG-IAP', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "GFDLCM3 = {'modn': 'GFDL-CM3', 'consort': 'NOAA-GFDL', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "GISSE2H = {'modn': 'GISS-E2-H', 'consort': 'NASA-GISS', 'cmip': 'cmip5',\n",
    "           'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "GISSE2R = {'modn': 'GISS-E2-R', 'consort': 'NASA-GISS', 'cmip': 'cmip5',\n",
    "           'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "IPSLCM5ALR = {'modn': 'IPSL-CM5A-LR', 'consort': 'IPSL', 'cmip': 'cmip5',\n",
    "               'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "MIROC5 = {'modn': 'MIROC5', 'consort': 'MIROC', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "MPIESMMR = {'modn': 'MPI-ESM-MR', 'consort': 'MPI-M', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "NorESM1M = {'modn': 'NorESM1-M', 'consort': 'NCC', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "\n",
    "MIROCESM = {'modn': 'MIROC-ESM', 'consort': 'MIROC', 'cmip': 'cmip5', \n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "MRICGCM3 = {'modn': 'MRI-CGCM3', 'consort': 'MRI', 'cmip': 'cmip5', \n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "MPIESMLR = {'modn': 'MPI-ESM-LR', 'consort': 'MPI-M', 'cmip': 'cmip5',\n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "bcccsm11 = {'modn': 'bcc-csm1-1', 'consort': 'BCC', 'cmip': 'cmip5', \n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "GFDLESM2G = {'modn': 'GFDL-ESM2G', 'consort': 'NOAA-GFDL', 'cmip': 'cmip5', \n",
    "            'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "GFDLESM2M = {'modn': 'GFDL-ESM2M', 'consort': 'NOAA-GFDL', 'cmip': 'cmip5', \n",
    "           'exper': exp, 'ensmem': 'r1i1p1', \"typevar\": 'Amon'}\n",
    "\n",
    "\n",
    "deck = [BCCESM1, CanESM5, CESM2, CESM2FV2, CESM2WACCM, CNRMESM21, GISSE21G, GISSE21H, IPSLCM6ALR, MRIESM20, MIROC6, SAM0, E3SM10, FGOALSg3, GFDLCM4, CAMSCSM1, INM_CM48, MPIESM12LR, AWICM11MR, BCCCSMCM2MR, CMCCCM2SR5, CESM2WACCMFV2, CNRMCM61, CNRMCM61HR, ECEarth3, ECEarth3Veg, GISSE22G, MIROCES2L, NESM3, NorESM2MM, TaiESM1, BNUESM, CCSM4, CNRMCM5, CSIRO_Mk360, CanESM2, FGOALSg2, FGOALSs2, GFDLCM3, GISSE2H, GISSE2R, IPSLCM5ALR, MIROC5, MPIESMMR, NorESM1M, MIROCESM, MRICGCM3, MPIESMLR, bcccsm11, GFDLESM2G, GFDLESM2M]   # current # 31 (no.19) + 20 = 51\n",
    "deck_nas = ['BCCESM1', 'CanESM5', 'CESM2', 'CESM2FV2', 'CESM2WACCM', 'CNRMESM21', 'GISSE21G', 'GISSE21H', 'IPSLCM6ALR', 'MRIESM20', 'MIROC6', 'SAM0', 'E3SM10', 'FGOALSg3', 'GFDLCM4', 'CAMSCSM1', 'INM_CM48', 'MPIESM12LR', 'AWICM11MR', 'BCCCSMCM2MR', 'CMCCCM2SR5', 'CESM2WACCMFV2', 'CNRMCM61', 'CNRMCM61HR', 'ECEarth3', 'ECEarth3Veg', 'GISSE22G', 'MIROCES2L', 'NESM3', 'NorESM2MM', 'TaiESM1', 'BNUESM', 'CCSM4', 'CNRMCM5', 'CSIRO_Mk360', 'CanESM2', 'FGOALSg2', 'FGOALSs2', 'GFDLCM3', 'GISSE2H', 'GISSE2R', 'IPSLCM5ALR', 'MIROC5', 'MPIESMMR', 'NorESM1M', 'MIROCESM', 'MRICGCM3', 'MPIESMLR', 'bcccsm11', 'GFDLESM2G', 'GFDLESM2M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c96570-a464-492b-9c14-ee09e63df991",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deck_nas = ['BCCESM1', 'CanESM5', 'CESM2', 'CESM2FV2', 'CESM2WACCM', 'CNRMESM21', 'GISSE21G', 'GISSE21H', 'IPSLCM6ALR', 'MRIESM20', 'MIROC6', 'SAM0', 'E3SM10', 'FGOALSg3', 'GFDLCM4', 'CAMSCSM1', 'INM_CM48', 'MPIESM12LR', 'AWICM11MR', 'BCCCSMCM2MR', 'CMCCCM2SR5', 'CESM2WACCMFV2', 'CNRMCM61', 'CNRMCM61HR', 'ECEarth3', 'ECEarth3Veg', 'GISSE22G', 'MIROCES2L', 'NESM3', 'NorESM2MM', 'TaiESM1', 'BNUESM', 'CCSM4', 'CNRMCM5', 'CSIRO_Mk360', 'CanESM2', 'FGOALSg2', 'FGOALSs2', 'GFDLCM3', 'GISSE2H', 'GISSE2R', 'IPSLCM5ALR', 'MIROC5', 'MPIESMMR', 'NorESM1M', 'MIROCESM', 'MRICGCM3', 'MPIESMLR', 'bcccsm11', ', GFDLESM2G', 'GFDLESM2M']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97efb0d-83b2-449f-bc22-c2197e40c84e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# calc_LRM_metric\n",
    "# fitLRM_cy1\n",
    "# fitLRM_cy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f98114-198d-419b-8131-63a85e4b9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data = GFDLCM3\n",
    "N_of_model = 38\n",
    "\n",
    "\n",
    "WD = '/glade/scratch/chuyan/CMIP_output/'\n",
    "\n",
    "folder = glob.glob(WD+ deck_nas[N_of_model]+'__'+ 'STAT_pi+abr_'+'22x_31y_Sep9th_anomalies'+'.npz')\n",
    "# print(folder)\n",
    "output_ARRAY = np.load(folder[0], allow_pickle=True)  # str(TR_sst)\n",
    "TR_sst1 = output_ARRAY['TR_minabias_SST']\n",
    "TR_sub1 = output_ARRAY['TR_minabias_SUB']\n",
    "TR_sst2 = output_ARRAY['TR_maxR2_SST']\n",
    "TR_sub2 = output_ARRAY['TR_maxR2_SUB']\n",
    "\n",
    "print(\"TR_min_abs(bias): \" , TR_sst1, '  K ', TR_sub1 , ' Pa/s ')\n",
    "print(\"TR_large_pi_R_2: \", TR_sst2, '  K ', TR_sub2 , ' Pa/s ')\n",
    "\n",
    "calc_LRM_metrics(float(TR_sst2), float(TR_sub2), **deck[N_of_model])\n",
    "THRESHOLD_sst = TR_sst2\n",
    "THRESHOLD_sub = TR_sub2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4166f-8676-4fa5-8f5c-0efb730d0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variable data\n",
    "if model_data['cmip'] == 'cmip6':\n",
    "\n",
    "    inputVar_pi, inputVar_abr = get_LWPCMIP6(**model_data)\n",
    "\n",
    "elif model_data['cmip'] == 'cmip5':\n",
    "\n",
    "    inputVar_pi, inputVar_abr = get_LWPCMIP5(**model_data)\n",
    "else:\n",
    "    print('not cmip6 & cmip5 data.')\n",
    "\n",
    "# ******************************* #\n",
    "# Radiation Change\n",
    "# coef_array_alpha_cre_pi, coef_array_albedo_pi, coef_array_alpha_cre_abr, coef_array_albedo_abr = calc_Radiation_LRM_1(inputVar_pi, inputVar_abr, TR_albedo = 0.25)\n",
    "coef_array_alpha_cre_pi, coef_array_albedo_pi, coef_array_alpha_cre_abr, coef_array_albedo_abr = calc_Radiation_LRM_2(inputVar_pi, inputVar_abr)\n",
    "\n",
    "# ******************************* #\n",
    "#..get the shapes of monthly data\n",
    "shape_lat = len(inputVar_pi['lat'])\n",
    "shape_lon = len(inputVar_pi['lon'])\n",
    "shape_time_pi = len(inputVar_pi['times'])\n",
    "shape_time_abr = len(inputVar_abr['times'])\n",
    "#print(shape_lat, shape_lon, shape_time_pi, shape_time_abr)\n",
    "\n",
    "\n",
    "#..choose lat 40 -85 Â°S as the Southern-Ocean Regions\n",
    "lons = inputVar_pi['lon'] *1.\n",
    "lats = inputVar_pi['lat'][:] *1.\n",
    "\n",
    "levels = array(inputVar_abr['pres'])\n",
    "times_abr = inputVar_abr['times'] *1.\n",
    "times_pi = inputVar_pi['times'] *1.\n",
    "\n",
    "lati0 = -40.\n",
    "latsi0= min(range(len(lats)), key = lambda i: abs(lats[i] - lati0))\n",
    "lati1 = -85.\n",
    "latsi1= min(range(len(lats)), key = lambda i: abs(lats[i] - lati1))\n",
    "print('lat index for 40.s; 85.s', latsi0, latsi1)\n",
    "\n",
    "shape_latSO =  (latsi0+1) - latsi1\n",
    "#print(shape_latSO)\n",
    "\n",
    "\n",
    "#..abrupt-4xCO2 Variables: LWP, tas(gmt), SST, (MC), p-e; SW radiation metrics\n",
    "LWP_abr = array(inputVar_abr['clwvi']) - array(inputVar_abr['clivi'])   #..units in kg m^-2\n",
    "\n",
    "gmt_abr = array(inputVar_abr['tas'])\n",
    "\n",
    "SST_abr = array(inputVar_abr['sfc_T'])\n",
    "\n",
    "Precip_abr = array(inputVar_abr['P']) * (24.*60.*60.)   #.. Precipitation. Convert the units from kg m^-2 s^-1 -> mm*day^-1\n",
    "print('abr4x average Pr(mm/ day): ', nanmean(Precip_abr))   #.. IPSL/abr2.80..  CNRM ESM2 1/abr 2.69.. CESM2/abr 2.74..\n",
    "lh_vaporization_abr = (2.501 - (2.361 * 10**-3) * (SST_abr - 273.15)) * 1e6  # the latent heat of vaporization at the surface Temperature\n",
    "# Eva_abr2 = array(inputVar_abr['E']) * (24. * 60 * 60)\n",
    "Eva_abr1 = array(inputVar_abr['E']) / lh_vaporization_abr * (24. * 60 * 60)  #.. Evaporation, mm day^-1\n",
    "print('abr4x average Evapor(mm/ day): ', nanmean(Eva_abr1))         #.. IPSL/abr2.50..  CNRM ESM2 1/abr 2.43.. CESM2/abr 2.43..\n",
    "MC_abr = Precip_abr - Eva_abr1   #..Moisture Convergence calculated from abrupt4xCO2's P - E, Units in mm day^-1\n",
    "\n",
    "Twp_abr = array(inputVar_abr['clwvi'])\n",
    "Iwp_abr = array(inputVar_abr['clivi'])\n",
    "\n",
    "# SW radiation metrics\n",
    "Rsdt_abr = array(inputVar_abr['rsdt'])\n",
    "Rsut_abr = array(inputVar_abr['rsut'])\n",
    "Rsutcs_abr = array(inputVar_abr['rsutcs'])\n",
    "print(\"shape of data in 'abrupt-4xCO2':  \",  Rsut_abr.shape, \" mean 'abrupt-4xCO2' upwelling SW radiation flux in the SO (Assume with cloud): \",  nanmean(Rsut_abr[:, latsi1:latsi0 +1,:]))\n",
    "print(\"shape of data in 'abrupt-4XCO2' exp:\", Eva_abr1.shape, 'abr4x mean-gmt(K): ', nanmean(gmt_abr))\n",
    "\n",
    "# albedo, albedo_clear sky, albedo_cre: all-sky - clear-sky\n",
    "Albedo_abr = Rsut_abr / Rsdt_abr\n",
    "Albedo_cs_abr = Rsutcs_abr / Rsdt_abr\n",
    "Alpha_cre_abr = Albedo_abr - Albedo_cs_abr\n",
    "\n",
    "if np.min(LWP_abr)<0:\n",
    "    LWP_abr = Twp_abr\n",
    "    print('clwvi mislabeled')\n",
    "\n",
    "#..piControl Variables: LWP, tas(gmt), SST, (MC), p-e ; SW radiation metrics (rsdt, rsut, rsutcs)\n",
    "LWP = array(inputVar_pi['clwvi']) - array(inputVar_pi['clivi'])   #..units in kg m^-2\n",
    "\n",
    "gmt = array(inputVar_pi['tas'])\n",
    "SST = array(inputVar_pi['sfc_T'])\n",
    "\n",
    "Precip = array(inputVar_pi['P'])* (24.*60.*60.)    #..Precipitation. Convert the units from kg m^-2 s^-1 -> mm*day^-1\n",
    "print('pi-C average Pr(mm/ day): ', nanmean(Precip))   #.. IPSL/piC 2.43..CNRM/piC 2.40.. CESM2/PIc 2.39\n",
    "lh_vaporization = (2.501 - (2.361 * 10**-3) * (SST - 273.15)) * 1e6  # the latent heat of vaporization at the surface Temperature\n",
    "Eva1 = array(inputVar_pi['E']) / lh_vaporization * (24. * 60 * 60)\n",
    "# Eva2 = array(inputVar_pi['E']) * (24.*60.*60.)   #..evaporation, mm day^-1\n",
    "\n",
    "print('pi-C average Evapor(mm/day): ', nanmean(Eva1))   #.. IPSL/piC  2.21..CNRM/piC 2.20.. CESM2/PIc 2.17..\n",
    "MC = Precip - Eva1   #..Moisture Convergence calculated from pi-Control's P - E, Units in mm day^-1\n",
    "\n",
    "Twp = array(inputVar_pi['clwvi'])\n",
    "Iwp = array(inputVar_pi['clivi'])\n",
    "\n",
    "\n",
    "# SW radiation metrics\n",
    "Rsdt_pi = array(inputVar_pi['rsdt'])\n",
    "Rsut_pi = array(inputVar_pi['rsut'])\n",
    "Rsutcs_pi = array(inputVar_pi['rsutcs'])\n",
    "print(\"shape of data in 'piControl':  \", Rsut_pi.shape, \" mean 'piControl' upwelling SW radiation flux in the SO (Assume with cloud): \"\n",
    ", nanmean(Rsut_pi[:, latsi1:latsi0 +1,:]))\n",
    "print(\"shape of data in 'piControl' data: \", Eva1.shape, 'pi-C mean-gmt(K): ', nanmean(gmt))\n",
    "\n",
    "# albedo, albedo_clear sky; albedo(alpha)_cre: all-sky - clear-sky\n",
    "Albedo_pi = Rsut_pi / Rsdt_pi\n",
    "Albedo_cs_pi = Rsutcs_pi / Rsdt_pi\n",
    "Alpha_cre_pi = Albedo_pi - Albedo_cs_pi\n",
    "\n",
    "if np.min(LWP)<0:\n",
    "    LWP = Twp\n",
    "    print('clwvi mislabeled')\n",
    "\n",
    "#..abrupt-4xCO2\n",
    "# Lower Tropospheric Stability (LTS):\n",
    "k = 0.286\n",
    "\n",
    "theta_700_abr = array(inputVar_abr['T_700']) * (100000./70000.)**k\n",
    "theta_skin_abr = array(inputVar_abr['sfc_T']) * (100000./array(inputVar_abr['sfc_P']))**k \n",
    "LTS_m_abr = theta_700_abr - theta_skin_abr\n",
    "\n",
    "#..Subtract the outliers in T_700 and LTS_m, 'nan' comes from missing T_700 data\n",
    "LTS_e_abr = ma.masked_where(theta_700_abr >= 500, LTS_m_abr)\n",
    "\n",
    "# Meteorology Subsidence at 500 hPa, units in Pa s^-1:\n",
    "Subsidence_abr = array(inputVar_abr['sub'])\n",
    "\n",
    "#.. piControl\n",
    "# Lower Tropospheric Stability (LTS):\n",
    "theta_700 = array(inputVar_pi['T_700']) * (100000./70000.)**k\n",
    "theta_skin = array(inputVar_pi['sfc_T']) * (100000./array(inputVar_pi['sfc_P']))**k\n",
    "LTS_m = theta_700 - theta_skin\n",
    "\n",
    "#..Subtract the outliers in T_700 and LTS_m \n",
    "LTS_e = ma.masked_where(theta_700 >= 500, LTS_m)\n",
    "\n",
    "#..Meteological Subsidence  at 500 hPa, units in Pa s^-1:\n",
    "Subsidence = array(inputVar_pi['sub'])\n",
    "\n",
    "# define Dictionary to store: CCFs(4), gmt, other variables :\n",
    "dict0_PI_var = {'gmt': gmt, 'LWP': LWP, 'TWP': Twp, 'IWP': Iwp, 'SST': SST, 'p_e': MC, 'LTS': LTS_e, 'SUB': Subsidence, 'rsdt': Rsdt_pi, 'rsut': Rsut_pi, 'rsutcs': Rsutcs_pi, 'albedo' : Albedo_pi, 'albedo_cs': Albedo_cs_pi, 'alpha_cre': Alpha_cre_pi, 'lat': lats, 'lon': lons, 'times': times_pi, 'pres': levels}\n",
    "\n",
    "dict0_abr_var = {'gmt': gmt_abr, 'LWP': LWP_abr, 'TWP': Twp_abr, 'IWP': Iwp_abr, 'SST': SST_abr, 'p_e': MC_abr, 'LTS': LTS_e_abr ,'SUB': Subsidence_abr, 'rsdt': Rsdt_abr, 'rsut': Rsut_abr, 'rsutcs': Rsutcs_abr, 'albedo': Albedo_abr, 'albedo_cs': Albedo_cs_abr, 'alpha_cre': Alpha_cre_abr, 'lat': lats, 'lon': lons, 'times': times_abr, 'pres': levels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b99f8-1901-4122-8c5d-7f80dfe3d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Annual-mean, Southern-Ocean region arrays\n",
    "\n",
    "datavar_nas = ['LWP', 'TWP', 'IWP', 'rsdt', 'rsut', 'rsutcs', 'albedo', 'albedo_cs', 'alpha_cre', 'SST', 'p_e', 'LTS', 'SUB']   #..13 varisables except gmt (lon dimension diff)\n",
    "\n",
    "dict1_PI_yr = {}\n",
    "dict1_abr_yr = {}\n",
    "shape_yr_pi = shape_time_pi//12\n",
    "shape_yr_abr = shape_time_abr//12\n",
    "\n",
    "layover_yr_abr = zeros((len(datavar_nas), shape_yr_abr, shape_latSO, shape_lon))\n",
    "layover_yr_pi = zeros((len(datavar_nas), shape_yr_pi, shape_latSO, shape_lon))\n",
    "\n",
    "layover_yr_abr_gmt = zeros((shape_yr_abr, shape_lat, shape_lon))\n",
    "layover_yr_pi_gmt = zeros((shape_yr_pi, shape_lat, shape_lon))\n",
    "\n",
    "\n",
    "for a in range(len(datavar_nas)):\n",
    "\n",
    "    # a_array = dict0_abr_var[datavar_nas[a]]\n",
    "\n",
    "    for i in range(shape_time_abr//12):\n",
    "        layover_yr_abr[a, i,:,:] = nanmean(dict0_abr_var[datavar_nas[a]][i*12:(i+1)*12, latsi1:latsi0 +1,:], axis=0)\n",
    "\n",
    "    dict1_abr_yr[datavar_nas[a]+'_yr'] = layover_yr_abr[a,:]\n",
    "\n",
    "\n",
    "    # b_array = dict0_PI_var[datavar_nas[a]]\n",
    "    for j in range(shape_time_pi//12):\n",
    "        layover_yr_pi[a, j,:,:] = nanmean(dict0_PI_var[datavar_nas[a]][j*12:(j+1)*12, latsi1:latsi0 +1,:], axis=0)\n",
    "\n",
    "    dict1_PI_yr[datavar_nas[a]+'_yr'] = layover_yr_pi[a,:]\n",
    "    print(datavar_nas[a])\n",
    "\n",
    "#print(dict1_PI_yr['LWP_yr'])\n",
    "\n",
    "# gmt\n",
    "for i in range(shape_time_abr//12):\n",
    "\n",
    "    layover_yr_abr_gmt[i,:,:] = nanmean(dict0_abr_var['gmt'][i*12:(i+1)*12, :,:], axis=0)\n",
    "dict1_abr_yr['gmt_yr'] = layover_yr_abr_gmt\n",
    "\n",
    "for j in range(shape_time_pi//12):\n",
    "    layover_yr_pi_gmt[j,:,:] = nanmean(dict0_PI_var['gmt'][j*12:(j+1)*12, :,:], axis=0)\n",
    "dict1_PI_yr['gmt_yr'] = layover_yr_pi_gmt\n",
    "\n",
    "# print(dict1_PI_yr['gmt_yr'])\n",
    "dict0_PI_var['dict1_yr'] = dict1_PI_yr\n",
    "dict0_abr_var['dict1_yr'] = dict1_abr_yr\n",
    "\n",
    "\n",
    "# Calculate 5*5 bin array for variables (LWP, CCFs) in Sounthern Ocean Region:\n",
    "#..set are-mean range and define function\n",
    "s_range = arange(-90., 90., 5.) + 2.5  #..global-region latitude edge: (36)\n",
    "x_range = arange(-180., 180., 5.)  #..logitude sequences edge: number: 72\n",
    "y_range = arange(-85, -40., 5.) +2.5  #..southern-ocaen latitude edge: 9\n",
    "\n",
    "# Annually variables in bin box:\n",
    "\n",
    "lat_array = lats[latsi1:latsi0+1] *1.\n",
    "lon_array = lons *1.\n",
    "lat_array1 = lats *1.\n",
    "\n",
    "dict1_PI_var = {}   #.. add at Dec.30th, at 2021. Purpose: shrink the output savez data dictionary: rawdata\n",
    "dict1_abr_var = {}   #.. add at Dec.30th, at 2021. Purpose: shrink the output savez data dictionary: rawdata\n",
    "dict1_yr_bin_PI = {}\n",
    "dict1_yr_bin_abr = {}\n",
    "\n",
    "for b in range(len(datavar_nas)):\n",
    "\n",
    "    dict1_yr_bin_abr[datavar_nas[b]+'_yr_bin'] = binned_cySouthOcean5(dict1_abr_yr[datavar_nas[b]+'_yr'], lat_array, lon_array)\n",
    "    dict1_yr_bin_PI[datavar_nas[b]+'_yr_bin'] = binned_cySouthOcean5(dict1_PI_yr[datavar_nas[b]+'_yr'], lat_array, lon_array)\n",
    "\n",
    "# print(dict1_yr_bin_abr['PRW_yr_bin'].shape)\n",
    "# print(dict1_yr_bin_abr['gmt_yr_bin'])  #..(150, 36, 73)\n",
    "# print(dict1_yr_bin_PI['SUB_yr_bin'].shape)  #..(100, 10, 73)\n",
    "dict1_yr_bin_abr['gmt_yr_bin'] = binned_cyGlobal5(dict1_abr_yr['gmt_yr'], lat_array1, lon_array)\n",
    "dict1_yr_bin_PI['gmt_yr_bin'] = binned_cyGlobal5(dict1_PI_yr['gmt_yr'], lat_array1, lon_array)\n",
    "print('gmt_yr_bin')\n",
    "\n",
    "dict1_abr_var['dict1_yr_bin_abr'] = dict1_yr_bin_abr\n",
    "dict1_PI_var['dict1_yr_bin_PI'] = dict1_yr_bin_PI\n",
    "\n",
    "# Monthly variables (same as above):\n",
    "dict1_mon_bin_PI = {}\n",
    "dict1_mon_bin_abr = {}\n",
    "\n",
    "for c in range(len(datavar_nas)):\n",
    "    dict1_mon_bin_abr[datavar_nas[c]+'_mon_bin'] = binned_cySouthOcean5(dict0_abr_var[datavar_nas[c]][0:, latsi1:latsi0+1,:], lat_array, lon_array)\n",
    "    dict1_mon_bin_PI[datavar_nas[c]+'_mon_bin'] = binned_cySouthOcean5(dict0_PI_var[datavar_nas[c]][0:, latsi1:latsi0+1,:], lat_array, lon_array)\n",
    "\n",
    "dict1_mon_bin_abr['gmt_mon_bin'] = binned_cyGlobal5(dict0_abr_var['gmt'][0:,:,:], lat_array1, lon_array)\n",
    "dict1_mon_bin_PI['gmt_mon_bin'] = binned_cyGlobal5(dict0_PI_var['gmt'][0:,:,:], lat_array1, lon_array)\n",
    "print(\"Every month monthly data\")\n",
    "\n",
    "dict1_abr_var['dict1_mon_bin_abr'] = dict1_mon_bin_abr\n",
    "dict1_PI_var['dict1_mon_bin_PI'] = dict1_mon_bin_PI\n",
    "\n",
    "\n",
    "# input the shapes of year and month of pi&abr exper into the raw data dictionaries:\n",
    "dict1_abr_var['shape_yr'] = shape_yr_abr\n",
    "dict1_PI_var['shape_yr'] = shape_yr_pi\n",
    "\n",
    "dict1_abr_var['shape_mon'] = shape_time_abr\n",
    "dict1_PI_var['shape_mon'] = shape_time_pi\n",
    "\n",
    "# Output a dict for processing function in 'calc_LRM_metrics', stored the data dicts for PI and abr, with the model name_dict\n",
    "C_dict = {'dict1_PI_var': dict1_PI_var, 'dict1_abr_var': dict1_abr_var, 'model_data': model_data, 'coef_array_alpha_cre_pi': coef_array_alpha_cre_pi, 'coef_array_albedo_pi': coef_array_albedo_pi, 'coef_array_alpha_cre_abr': coef_array_alpha_cre_abr, 'coef_array_albedo_abr': coef_array_albedo_abr}  #..revised on June 23th, 2022.\n",
    "D_dict = deepcopy(C_dict)   # 'notice for the difference between shallow copy (object.copy()) and deep copy(copy.deepcopy(object))'\n",
    "B_dict = deepcopy(C_dict)\n",
    "\n",
    "###..Put data into 'fitLRM' FUNCTION to get predicted LWP splitted by 'Tr_sst'/'Tr_sub' infos_models:\n",
    "WD = '/glade/scratch/chuyan/CMIP_output/CMIP_lrm_RESULT/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894f719-1851-441a-98d6-e8c04f8e2ee1",
   "metadata": {},
   "source": [
    "fitLRM_cy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f049d05-4eb8-4395-a471-6fbec32e1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_dict = B_dict\n",
    "TR_sst = THRESHOLD_sst   ###.. threshold skin T\n",
    "TR_sub = THRESHOLD_sub   ###.. threshold of 500 mb Subsidence\n",
    "s_range = s_range\n",
    "y_range = y_range\n",
    "x_range = x_range\n",
    "lats = lats\n",
    "lons = lons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82833116-c41d-4372-83ba-5043fd0f097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C_dict' is the raw data dict, 'TR_sst' is the pre-defined skin_Temperature Threshold to distinguish two Multi-Linear Regression Models\n",
    "\n",
    "# 's_range , 'y_range', 'x_range' used to do area mean for repeat gmt ARRAY\n",
    "\n",
    "dict0_abr_var = C_dict['dict1_abr_var']\n",
    "dict0_PI_var  = C_dict['dict1_PI_var']\n",
    "#print(dict0_PI_var['times'])\n",
    "\n",
    "model = C_dict['model_data']   #.. type in dict\n",
    "\n",
    "datavar_nas = ['LWP', 'TWP', 'IWP', 'rsdt', 'rsut', 'rsutcs', 'albedo', 'albedo_cs', 'SST', 'p_e', 'LTS', 'SUB']   #..12 varisables except gmt (lon dimension  diff)\n",
    "\n",
    "# load annually-mean bin data.\n",
    "dict1_yr_bin_PI = dict0_PI_var['dict1_yr_bin_PI']\n",
    "dict1_yr_bin_abr = dict0_abr_var['dict1_yr_bin_abr']\n",
    "#print(dict1_yr_bin_PI['LWP_yr_bin'].shape)\n",
    "\n",
    "# load monthly bin data.\n",
    "dict1_mon_bin_PI = dict0_PI_var['dict1_mon_bin_PI']\n",
    "dict1_mon_bin_abr = dict0_abr_var['dict1_mon_bin_abr']\n",
    "\n",
    "# data array in which shapes?\n",
    "shape_yr_PI = dict1_yr_bin_PI['LWP_yr_bin'].shape\n",
    "shape_yr_abr = dict1_yr_bin_abr['LWP_yr_bin'].shape\n",
    "\n",
    "shape_yr_PI_gmt = dict1_yr_bin_PI['gmt_yr_bin'].shape\n",
    "shape_yr_abr_gmt = dict1_yr_bin_abr['gmt_yr_bin'].shape\n",
    "\n",
    "shape_mon_PI = dict1_mon_bin_PI['LWP_mon_bin'].shape\n",
    "shape_mon_abr = dict1_mon_bin_abr['LWP_mon_bin'].shape\n",
    "\n",
    "shape_mon_PI_gmt = dict1_mon_bin_PI['gmt_mon_bin'].shape\n",
    "shape_mon_abr_gmt = dict1_mon_bin_abr['gmt_mon_bin'].shape\n",
    "\n",
    "\n",
    "#.. archieve the 'shape' infos: 3-D\n",
    "C_dict['shape_yr_PI_3'] = shape_yr_PI\n",
    "C_dict['shape_yr_abr_3'] = shape_yr_abr\n",
    "C_dict['shape_yr_PI_gmt_3'] = shape_yr_PI_gmt\n",
    "C_dict['shape_yr_abr_gmt_3'] = shape_yr_abr_gmt\n",
    "\n",
    "C_dict['shape_mon_PI_3'] = shape_mon_PI\n",
    "C_dict['shape_mon_abr_3'] = shape_mon_abr\n",
    "C_dict['shape_mon_PI_gmt_3'] = shape_mon_PI_gmt\n",
    "C_dict['shape_mon_abr_gmt_3'] = shape_mon_abr_gmt\n",
    "\n",
    "# flatten the data array for 'training' lrm  coefficience\n",
    "\n",
    "dict2_predi_fla_PI = {}\n",
    "dict2_predi_fla_abr = {}\n",
    "\n",
    "dict2_predi_ano_PI = {}  # need a climatological arrays of variables\n",
    "dict2_predi_ano_abr = {}  # need a climatological arrays of variables\n",
    "\n",
    "dict2_predi_nor_PI = {}  # standardized anomalies of variables\n",
    "dict2_predi_nor_abr = {}\n",
    "\n",
    "dict2_predi = {}\n",
    "\n",
    "#.. Ravel binned array /Standardized data ARRAY :\n",
    "for d in range(len(datavar_nas)):\n",
    "\n",
    "    dict2_predi_fla_PI[datavar_nas[d]] = dict1_mon_bin_PI[datavar_nas[d]+'_mon_bin'].flatten()\n",
    "    dict2_predi_fla_abr[datavar_nas[d]] = dict1_mon_bin_abr[datavar_nas[d]+'_mon_bin'].flatten()\n",
    "\n",
    "    # anomalies in the raw units:\n",
    "    # 'dict2_predi' as a dict for reference-period (mean state) data\n",
    "    dict2_predi[datavar_nas[d]] = deepcopy(dict1_mon_bin_PI[datavar_nas[d]+'_mon_bin'])\n",
    "\n",
    "    dict2_predi_ano_PI[datavar_nas[d]] = dict2_predi_fla_PI[datavar_nas[d]] - nanmean(area_mean(dict2_predi[datavar_nas[d]], y_range, x_range))\n",
    "    dict2_predi_ano_abr[datavar_nas[d]] = dict2_predi_fla_abr[datavar_nas[d]] - nanmean(area_mean(dict2_predi[datavar_nas[d]], y_range,x_range))\n",
    "\n",
    "    # normalized stardard deviation in unit of './std':\n",
    "    dict2_predi_nor_PI[datavar_nas[d]] = dict2_predi_ano_PI[datavar_nas[d]] / nanstd(dict2_predi_fla_PI[datavar_nas[d]])  # divided by monthly standard variance\n",
    "    dict2_predi_nor_abr[datavar_nas[d]] = dict2_predi_ano_abr[datavar_nas[d]] / nanstd(dict2_predi_fla_PI[datavar_nas[d]])\n",
    "\n",
    "#..Use area_mean method, 'np.repeat' and 'np.tile' to reproduce gmt area-mean Array as the same shape as other flattened variables\n",
    "GMT_pi_mon = area_mean(dict1_mon_bin_PI['gmt_mon_bin'], s_range,  x_range)   #.. MONTHLY time series of global area_mean surface air temperature\n",
    "GMT_abr_mon = area_mean(dict1_mon_bin_abr['gmt_mon_bin'], s_range, x_range)   #.. MONTHLY time series of global area_mean surface air temperature\n",
    "\n",
    "# Use the southernOCEAN value as the gmt variable\n",
    "dict2_predi_fla_PI['gmt'] = GMT_pi_mon\n",
    "dict2_predi_fla_abr['gmt'] = GMT_abr_mon\n",
    "dict2_predi['gmt'] = deepcopy(dict2_predi_fla_PI['gmt'])\n",
    "shape_whole_period = asarray(dict2_predi['gmt'].shape[0])\n",
    "\n",
    "dict2_predi_ano_abr['gmt'] = dict2_predi_fla_abr['gmt'] - np.nanmean(dict2_predi['gmt'])  # shape in (t, lat, lon).flatten()\n",
    "dict2_predi_ano_PI['gmt'] = dict2_predi_fla_PI['gmt'] - np.nanmean(dict2_predi['gmt'])  # shape in (t, lat, lon).flatten()\n",
    "\n",
    "dict2_predi_nor_abr['gmt'] = dict2_predi_ano_abr['gmt'] / np.nanstd(dict2_predi_fla_PI['gmt'])\n",
    "dict2_predi_nor_PI['gmt'] = dict2_predi_ano_PI['gmt'] / np.nanstd(dict2_predi_fla_PI['gmt'])\n",
    "\n",
    "# shape of flattened array:\n",
    "metric_training = deepcopy(dict2_predi_nor_PI)\n",
    "metric_predict = deepcopy(dict2_predi_nor_abr)\n",
    "\n",
    "shape_fla_PI = dict2_predi_fla_PI['LWP'].shape\n",
    "shape_fla_abr = dict2_predi_fla_abr['LWP'].shape\n",
    "\n",
    "# save into rawdata_dict:\n",
    "C_dict['metric_training'] = dict2_predi_nor_PI\n",
    "C_dict['metric_predict'] = dict2_predi_nor_abr\n",
    "C_dict['GMT_training'] = GMT_pi_mon\n",
    "C_dict['GMT_predict'] = GMT_abr_mon\n",
    "\n",
    "C_dict['Mean_training'] = nanmean(area_mean(dict2_predi['LWP'], y_range, x_range))\n",
    "C_dict['Stdev_training'] = nanstd(dict2_predi_fla_PI['LWP'])\n",
    "print(C_dict['Mean_training'], C_dict['Stdev_training'])\n",
    "\n",
    "# shape of flattened array:\n",
    "metric_training = deepcopy(dict2_predi_nor_PI)\n",
    "metric_predict = deepcopy(dict2_predi_nor_abr)\n",
    "\n",
    "shape_fla_PI = dict2_predi_fla_PI['LWP'].shape\n",
    "shape_fla_abr = dict2_predi_fla_abr['LWP'].shape\n",
    "\n",
    "\n",
    "# The thresholds: TR_SST, TR_SUB:\n",
    "'''\n",
    "TR_sst_ano = TR_sst - np.nanmean(area_mean(dict2_predi['SST'], y_range, x_range))\n",
    "TR_sub_ano = TR_sub - np.nanmean(area_mean(dict2_predi['SUB'], y_range, x_range))\n",
    "\n",
    "TR_sst_nor = TR_sst_ano / np.nanstd(dict2_predi['SST'].flatten())\n",
    "TR_sub_nor = TR_sub_ano / np.nanstd(dict2_predi['SUB'].flatten())\n",
    "print('Threhold_anomalies: ', TR_sst_ano, TR_sub_ano)\n",
    "print('Threhold_normalized: ', TR_sst_nor, TR_sub_nor)\n",
    "'''\n",
    "\n",
    "#.. Training Module (2 lrm, with Up & Down)\n",
    "#.. piControl\n",
    "\n",
    "predict_dict_PI, ind7_PI, ind8_PI, ind9_PI, ind10_PI, coef_array, shape_fla_training = rdlrm_4_training(metric_training, TR_sst, TR_sub, predictant='LWP', r = 2)\n",
    "# predict_dict_PI_iwp, ind7_PI_iwp, ind8_PI_iwp, ind9_PI_iwp, ind10_PI_iwp, coef_array_iwp, shape_fla_training_iwp = rdlrm_4_training(metric_training, TR_sst_nor, TR_sub_nor, predictant='IWP', r = 2)\n",
    "'''\n",
    "predict_dict_PI_albedo, _, _, _, _, coef_array_albedo = rdlrm_4_training(metric_training, TR_sst_nor, TR_sub_nor, predictant='albedo', predictor=['LWP', 'albedo_cs'], r = 2)[0:6]\n",
    "predict_dict_PI_rsut, _, _, _, _, coef_array_rsut = rdlrm_4_training(metric_training, TR_sst_nor, TR_sub_nor, predictant='rsut', predictor=['LWP', 'rsutcs'], r = 2)[0:6]\n",
    "'''\n",
    "# Added on May 13th, 2022: for second step using LWP to predict the albedo\n",
    "'''\n",
    "dict2_predi_fla_PI['LWP_lrm'] = deepcopy(predict_dict_PI['value'])\n",
    "dict2_predi_ano_PI['LWP_lrm'] = dict2_predi_fla_PI['LWP_lrm'] - nanmean(area_mean( dict2_predi_fla_PI['LWP_lrm'].reshape(shape_mon_PI), y_range, x_range))\n",
    "dict2_predi_nor_PI['LWP_lrm'] = dict2_predi_ano_PI['LWP_lrm'] / nanstd(dict2_predi_fla_PI['LWP_lrm'])\n",
    "predict_dict_PI_albedo_lL, _, _, _, _, coef_array_albedo_lL = rdlrm_4_training(dict2_predi_fla_PI, TR_sst, TR_sub, predictant='albedo', predictor=['LWP_lrm', 'albedo_cs'], r  = 2)[0:6]\n",
    "predict_dict_PI_rsut_lL, _, _, _, _, coef_array_rsut_lL = rdlrm_4_training(dict2_predi_fla_PI, TR_sst, TR_sub, predictant='rsut', predictor=['LWP_lrm', 'rsutcs'], r = 2)[0:6]\n",
    "'''\n",
    "# Save into the rawdata dict\n",
    "C_dict['Coef_dict'] = coef_array\n",
    "C_dict['Predict_dict_PI']  = predict_dict_PI\n",
    "C_dict['ind_Up_PI'] = ind7_PI  # C_dict['ind_Cold_Up_PI'] = ind7_PI\n",
    "C_dict['ind_Down_PI'] = ind8_PI  # C_dict['ind_Hot_Up_PI'] = ind8_PI\n",
    "# C_dict['Coef_dict_IWP']= coef_array_iwp\n",
    "# C_dict['Predict_dict_PI_IWP']  = predict_dict_PI_iwp\n",
    "\n",
    "# 'YB' is the predicted value of LWP in 'piControl' experiment\n",
    "YB = predict_dict_PI['value']\n",
    "# YB_iwp = predict_dict_PI_iwp['value']\n",
    "\n",
    "# Save 'YB', resampled into the shape of 'LWP_yr_bin':\n",
    "C_dict['LWP_predi_bin_PI'] = asarray(YB).reshape(shape_mon_PI)\n",
    "# C_dict['IWP_predi_bin_PI'] = asarray(YB_iwp).reshape(shape_mon_PI)\n",
    "\n",
    "# Test performance\n",
    "stats_dict_PI = Test_performance_2(metric_training['LWP'], YB, ind7_PI, ind8_PI)   #  Test_performance_4(dict2_predi_fla_PI['LWP'], YB, ind7_PI, ind8_PI, ind9_PI, ind10_PI)\n",
    "# stats_dict_PI_iwp = Test_performance_2(metric_training['IWP'], YB_iwp, ind7_PI_iwp, ind8_PI_iwp)   # Test_performance_4(dict2_predi_fla_PI['IWP'], YB_iwp, ind7_PI_iwp, ind8_PI_iwp, ind9_PI_iwp, ind10_PI_iwp)\n",
    "\n",
    "\n",
    "#.. predict Module (2LRM-Up & Down)\n",
    "#.. abrupt 4xCO2\n",
    "\n",
    "predict_dict_abr, ind7_abr, ind8_abr, ind9_abr, ind10_abr, shape_fla_testing = rdlrm_4_predict(metric_predict, coef_array, TR_sst, TR_sub, predictant = 'LWP', predictor = ['SST', 'p_e', 'LTS', 'SUB'], r = 2)\n",
    "# predict_dict_abr_iwp, ind7_abr_iwp, ind8_abr_iwp, ind9_abr_iwp, ind10_abr_iwp, shape_fla_testing_iwp = rdlrm_4_predict(metric_predict coef_array_iwp, TR_sst_nor, TR_sub_nor, predictant = 'IWP', predictor = ['SST', 'p_e', 'LTS', 'SUB'], r = 2)\n",
    "\n",
    "# Added on May 14th, 2022: for second step using LWP to predict the albedo\n",
    "'''\n",
    "# dict2_predi_fla_abr['LWP_lrm'] = deepcopy(predict_dict_abr['value'])\n",
    "# dict2_predi_ano_abr['LWP_lrm'] = dict2_predi_fla_abr['LWP_lrm'] - nanmean(area_mean( dict2_predi_fla_PI['LWP_lrm'].reshape(shape_mon_abr), y_range, x_range))\n",
    "# dict2_predi_nor_abr['LWP_lrm'] = (dict2_predi_fla_abr['LWP_lrm'] / nanstd(dict2_predi_fla_abr['LWP_lrm'])\n",
    "# predict_dict_abr_albedo_lL = rdlrm_4_predict(dict2_predi_fla_abr, coef_array_albedo, TR_sst, TR_sub, predictant='albedo', predictor=['LWP_lrm', 'albedo_cs'], r = 2)[0]\n",
    "# predict_dict_abr_rsut_lL = rdlrm_4_predict(dict2_predi_fla_abr, coef_array_rsut, TR_sst, TR_sub, predictant='rsut', predictor=['LWP_lrm', 'rsutcs'], r = 2)[0]\n",
    "'''\n",
    "# Save into the rawdata dict\n",
    "C_dict['Predict_dict_abr'] = predict_dict_abr\n",
    "C_dict['ind_Up_abr'] = ind7_abr  # C_dict['ind_Cold_Up_abr'] = ind7_abr\n",
    "C_dict['ind_Down_abr'] = ind8_abr  # C_dict['ind_Hot_Up_abr'] = ind8_abr\n",
    "# C_dict['Predict_dict_abr_IWP'] = predict_dict_abr_iwp\n",
    "\n",
    "# 'YB_abr' is the predicted value of LWP in 'abrupt-4xCO2' experiment\n",
    "YB_abr = predict_dict_abr['value']\n",
    "# YB_abr_iwp = predict_dict_abr_iwp['value']\n",
    "\n",
    "# Save 'YB_abr', reshapled into the shape of 'LWP_yr_bin_abr':\n",
    "C_dict['LWP_predi_bin_abr'] = asarray(YB_abr).reshape(shape_mon_abr)\n",
    "# C_dict['IWP_predi_bin_abr'] = asarray(YB_abr_iwp).reshape(shape_mon_abr)\n",
    "\n",
    "# Test performance for abrupt4xCO2 \n",
    "stats_dict_abr = Test_performance_2(metric_predict['LWP'], YB_abr, ind7_abr, ind8_abr)  # Test_performance_4(dict2_predi_fla_abr['LWP'], YB_abr, ind7_abr, ind8_abr, ind9_abr, ind10_abr)\n",
    "# stats_dict_abr_iwp = Test_performance_2(metric_predict['IWP'], YB_abr_iwp, ind7_abr_iwp, ind8_abr_iwp)  # Test_performance_4(dict2_predi_fla_abr['IWP'], YB_abr_iwp, ind7_abr_iwp, ind8_abr_iwp, ind9_abr_iwp, ind10_abr_iwp)\n",
    "\n",
    "#.. save preditc metrics into rawdata_dict\n",
    "C_dict['stats_dict_PI'] = stats_dict_PI\n",
    "# C_dict['stats_dict_PI_iwp'] = stats_dict_PI_iwp\n",
    "\n",
    "C_dict['stats_dict_abr'] = stats_dict_abr\n",
    "# C_dict['stats_dict_abr_iwp'] = stats_dict_abr_iwp\n",
    "\n",
    "# return C_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02c8ff-c917-429c-87b0-a1d144aa2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_training = C_dict['Mean_training'], \n",
    "Stdev_training = C_dict['Stdev_training']\n",
    "shape_yr_pi = shape_yr_pi\n",
    "shape_yr_abr = shape_yr_abr\n",
    "rawdata_dict = C_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c2a1c-6d12-4cb5-a487-3382fd3c87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 's_range , 'y_range', 'x_range' used to do area mean for repeat gmt ARRAY\n",
    "\n",
    "# retriving datas from big dict...\n",
    "dict0_abr_var = rawdata_dict['dict1_abr_var']\n",
    "dict0_PI_var = rawdata_dict['dict1_PI_var']\n",
    "shape_yr_PI_3 = rawdata_dict['shape_yr_PI_3']\n",
    "shape_yr_abr_3 = rawdata_dict['shape_yr_abr_3']\n",
    "shape_mon_PI_3 = rawdata_dict['shape_mon_PI_3']\n",
    "shape_mon_abr_3 = rawdata_dict['shape_mon_abr_3']\n",
    "\n",
    "model = rawdata_dict['model_data']   #.. type in dict\n",
    "\n",
    "datarepo_nas = ['LWP']  # 'IWP', albedo', 'albedo_cs', 'rsut', 'rsutcs'\n",
    "\n",
    "# load annually-mean bin data:\n",
    "dict1_yr_bin_PI = deepcopy(dict0_PI_var['dict1_yr_bin_PI'])\n",
    "dict1_yr_bin_abr = deepcopy(dict0_abr_var['dict1_yr_bin_abr'])\n",
    "\n",
    "# load monthly bin data:\n",
    "dict1_mon_bin_PI = deepcopy(dict0_PI_var['dict1_mon_bin_PI'])\n",
    "dict1_mon_bin_abr = deepcopy(dict0_abr_var['dict1_mon_bin_abr'])\n",
    "\n",
    "# load anomalies (or normalized) monthly bin data:\n",
    "dict_metric_actual_PI = deepcopy(rawdata_dict['metric_training'])\n",
    "dict_metric_actual_abr = deepcopy(rawdata_dict['metric_predict'])\n",
    "\n",
    "# load normalized predicted bin data:\n",
    "LWP_metric_predi_PI = deepcopy(rawdata_dict['LWP_predi_bin_PI'])\n",
    "LWP_metric_predi_abr = deepcopy(rawdata_dict['LWP_predi_bin_abr'])\n",
    "\n",
    "# calculate (convert) the predicted data back to raw unit:\n",
    "LWP_raw_predi_PI = (LWP_metric_predi_PI * Stdev_training) + Mean_training  # + Mean_training\n",
    "LWP_raw_predi_abr = (LWP_metric_predi_abr * Stdev_training) + Mean_training  # + Mean_training\n",
    "\n",
    "## Calc annually-mean, area-mean variables on 'abrupt4xCO2' and 'piControl' exps:\n",
    "# GCM actual variable\n",
    "areamean_dict_PI = {}\n",
    "areamean_dict_abr = {}\n",
    "\n",
    "for e in range(len(datarepo_nas)):\n",
    "\n",
    "    #  \"monthly\" convert to \"annually\":\n",
    "    areamean_dict_PI[datarepo_nas[e]+ '_yr_bin'] = get_annually_metric(dict_metric_actual_PI['LWP'].reshape(shape_mon_PI_3), shape_mon_PI_3[0], shape_mon_PI_3[1], shape_mon_PI_3[2]) \n",
    "    areamean_dict_abr[datarepo_nas[e]+ '_yr_bin'] = get_annually_metric(dict_metric_actual_abr['LWP'].reshape(shape_mon_abr_3), shape_mon_abr_3[0], shape_mon_abr_3[1], shape_mon_abr_3[2])\n",
    "    \n",
    "    # \"yr_bin\" area_mean to 'shape_yr_':\n",
    "    areamean_dict_PI[datarepo_nas[e]+ '_area_yr'] = area_mean(areamean_dict_PI[datarepo_nas[e]+ '_yr_bin'], y_range, x_range)\n",
    "    areamean_dict_abr[datarepo_nas[e]+ '_area_yr'] = area_mean(areamean_dict_abr[datarepo_nas[e]+ '_yr_bin'], y_range, x_range)\n",
    "\n",
    "areamean_dict_PI['gmt_area_yr'] = area_mean(dict1_yr_bin_PI['gmt_yr_bin'], s_range, x_range)\n",
    "areamean_dict_abr['gmt_area_yr'] = area_mean(dict1_yr_bin_abr['gmt_yr_bin'], s_range, x_range)\n",
    "\n",
    "\n",
    "# LRM predict variable\n",
    "areamean_dict_predi =  {}\n",
    "datapredi_nas = ['LWP']  # 'IWP', 'albedo', 'rsut', 'albedo_lL', 'rsut_lL'\n",
    "\n",
    "for f in range(len(datapredi_nas)):\n",
    "    areamean_dict_predi[datapredi_nas[f]+'_predi_yr_bin_pi'] = get_annually_metric(rawdata_dict[datapredi_nas[f]+'_predi_bin_PI'], shape_mon_PI_3[0], shape_mon_PI_3[1], shape_mon_PI_3[2])\n",
    "    areamean_dict_predi[datapredi_nas[f]+'_predi_yr_bin_abr'] = get_annually_metric(rawdata_dict[datapredi_nas[f]+'_predi_bin_abr'], shape_mon_abr_3[0], shape_mon_abr_3[1], shape_mon_abr_3[2])\n",
    "\n",
    "# \"yr_bin\" area_mean to 'shape_yr_':\n",
    "for g in range(len(datapredi_nas)):\n",
    "\n",
    "    areamean_dict_predi[datapredi_nas[g]+'_area_yr_pi'] = area_mean(areamean_dict_predi[datapredi_nas[g]+'_predi_yr_bin_pi'], y_range, x_range)\n",
    "    areamean_dict_predi[datapredi_nas[g]+'_area_yr_abr'] = area_mean(areamean_dict_predi[datapredi_nas[g]+'_predi_yr_bin_abr'], y_range, x_range)\n",
    "\n",
    "# Store the annually report & predicted metrics\n",
    "rawdata_dict['areamean_dict_predi'] = areamean_dict_predi\n",
    "rawdata_dict['areamean_dict_abr'] = areamean_dict_abr\n",
    "rawdata_dict['areamean_dict_PI'] = areamean_dict_PI\n",
    "\n",
    "# calc d_DeltaLWP /d_DeltaGMT |(abrupt-4xCO2 - avg(piControl)) add June 27th.\n",
    "output_2report_pi = area_mean(get_annually_metric(dict1_mon_bin_PI['LWP_mon_bin'],shape_mon_PI_3[0],shape_mon_PI_3[1],shape_mon_PI_3[2]), y_range, x_range)[:]\n",
    "output_2report_abr = area_mean(get_annually_metric(dict1_mon_bin_abr['LWP_mon_bin'],shape_mon_abr_3[0],shape_mon_abr_3[1],shape_mon_abr_3[2]), y_range, x_range)[0:150]\n",
    "\n",
    "output_2predict_pi = area_mean(get_annually_metric(LWP_raw_predi_PI, shape_mon_PI_3[0],shape_mon_PI_3[1],shape_mon_PI_3[2]), y_range, x_range)[:]\n",
    "output_2predict_abr = area_mean(get_annually_metric(LWP_raw_predi_abr, shape_mon_abr_3[0],shape_mon_abr_3[1],shape_mon_abr_3[2]), y_range, x_range)[0:150]\n",
    "\n",
    "output_yrs = arange(99 + 150)\n",
    "\n",
    "output_dabrmeanpi_report2 = output_2report_abr[0:150] - nanmean(output_2report_pi[0:99])\n",
    "output_dabrmeanpi_predict2 = areamean_dict_predi['LWP_area_yr_abr'][0:150] - nanmean(areamean_dict_predi['LWP_area_yr_pi'][0:99])\n",
    "output_dabrmeanpi_GMT2 = areamean_dict_abr['gmt_area_yr'][0:150] - mean(areamean_dict_PI['gmt_area_yr'])\n",
    "\n",
    "# regressed delta_LWP over delta_GMT, using 'statsmodels' ols functions\n",
    "data = pd.DataFrame({'x': output_dabrmeanpi_GMT2, 'y1':output_dabrmeanpi_report2, 'y2':output_dabrmeanpi_predict2})\n",
    "\n",
    "model_report = ols(\"y1 ~ x\", data).fit()\n",
    "model_predicted = ols(\"y2 ~ x\", data).fit()\n",
    "\n",
    "print(\" d_LWP/d_GMT model report summary: \", model_report._results.params[1], model_report._results.params[0])\n",
    "print(\" d_LWP/d_GMT model predict summary: \", model_predicted._results.params[1], model_predicted._results.params[0])\n",
    "\n",
    "#..save into rawdata_dict\n",
    "Dx_DtG = asarray([[model_report._results.params[1], model_report._results.params[0]], [model_predicted._results.params[1], model_predicted._results.params[0]]])\n",
    "rawdata_dict['dX_dTg'] = Dx_DtG\n",
    "\n",
    "\n",
    "# Generate continous annually-mean array are convenient for plotting LWP changes:\n",
    "#..Years from 'piControl' to 'abrupt4xCO2' experiment, which are choosed years\n",
    "Yrs = arange(shape_yr_pi + areamean_dict_abr['gmt_area_yr'].shape[0])\n",
    "rawdata_dict['Yrs'] = Yrs\n",
    "\n",
    "# global-mean surface air temperature, from 'piControl' to 'abrupt4xCO2' experiment:\n",
    "\n",
    "GMT = full((shape_yr_pi + areamean_dict_abr['gmt_area_yr'].shape[0]),  0.0)\n",
    "GMT[0:shape_yr_pi] = areamean_dict_PI['gmt_area_yr']\n",
    "GMT[shape_yr_pi:] = areamean_dict_abr['gmt_area_yr']\n",
    "rawdata_dict['GMT'] = GMT\n",
    "# LRM predict annually mean, area-mean values, from 'piControl' to 'abrupt4xCO2' experiment\n",
    "predict_metrics_annually = {}\n",
    "report_metrics_annually = {}\n",
    "\n",
    "for h in range(len(datapredi_nas)):\n",
    "    predict_metrics_annually[datapredi_nas[h]] = full((shape_yr_pi + areamean_dict_predi[datapredi_nas[h] + '_area_yr_abr'].shape[0]), 0.0)\n",
    "    predict_metrics_annually[datapredi_nas[h]][0:shape_yr_pi] = areamean_dict_predi[datapredi_nas[h] + '_area_yr_pi'][0:shape_yr_pi]\n",
    "    predict_metrics_annually[datapredi_nas[h]][shape_yr_pi:(shape_yr_pi + areamean_dict_predi[datapredi_nas[h] + '_area_yr_abr'].shape[0])] = areamean_dict_predi[datapredi_nas[h]+'_area_yr_abr']\n",
    "\n",
    "# GCM actual annually mean, area-mean values, from 'piControl' to 'abrupt4xCO2' experiment\n",
    "\n",
    "for i in range(len(datarepo_nas)):\n",
    "    report_metrics_annually[datarepo_nas[i]] = full((shape_yr_pi + areamean_dict_abr[datarepo_nas[i] + '_area_yr'].shape[0]), 0.0)  \n",
    "    report_metrics_annually[datarepo_nas[i]][0:shape_yr_pi] = areamean_dict_PI[datarepo_nas[i] + '_area_yr'][0:shape_yr_pi]\n",
    "    report_metrics_annually[datarepo_nas[i]][shape_yr_pi:(shape_yr_pi+areamean_dict_abr[datarepo_nas[i] + '_area_yr'].shape[0])] = areamean_dict_abr[datarepo_nas[i]+'_area_yr']\n",
    "\n",
    "print(\"report LWP: \", report_metrics_annually['LWP'])\n",
    "print(\"predicted LWP: \", predict_metrics_annually['LWP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff64637-3dcd-403c-8c99-d9bdbf69c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LWP_raw_actual_PI = (dict_metric_actual_PI['LWP'] * Stdev_training) + Mean_training  # + Mean_training\n",
    "LWP_raw_actual_abr = (dict_metric_actual_abr['LWP']* Stdev_training) + Mean_training \n",
    "\n",
    "print(LWP_raw_actual_abr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276b665-ab24-4b26-b2f9-8ea7dbac0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modn = 'GFDLCM3'\n",
    "type_analysis = 'forecasting'\n",
    "\n",
    "# get cmip6 data:\n",
    "name_j = 0\n",
    "while name_j < len(deck_nas):\n",
    "\n",
    "    if modn == deck_nas[name_j]:\n",
    "        print(\"No. of models: \", name_j)\n",
    "        if (deck[name_j]['cmip']=='cmip6') & (type_analysis == 'forecasting'):\n",
    "            inputVar_pi, inputVar_abr = get_LWPCMIP6(**deck[name_j])\n",
    "        elif (deck[name_j]['cmip']=='cmip5') & (type_analysis == 'forecasting'):\n",
    "            inputVar_pi, inputVar_abr = get_LWPCMIP5(**deck[name_j])\n",
    "        else:\n",
    "            print('No existing data of this model in chuyan scratch space.')\n",
    "        break\n",
    "\n",
    "    name_j += 1\n",
    "\n",
    "# begin process data:\n",
    "#..get the shapes of monthly data\n",
    "shape_lat = len(inputVar_pi['lat'])\n",
    "shape_lon = len(inputVar_pi['lon'])\n",
    "shape_time_pi = len(inputVar_pi['times'])\n",
    "shape_time_abr = len(inputVar_abr['times'])\n",
    "#print(shape_lat, shape_lon, shape_time_pi, shape_time_abr)\n",
    "\n",
    "\n",
    "#..choose lat 40 -85 Â°S as the Southern-Ocean Regions\n",
    "lons        = inputVar_pi['lon']\n",
    "lats        = inputVar_pi['lat'][:]\n",
    "\n",
    "levels      = array(inputVar_abr['pres'])\n",
    "times_abr   = inputVar_abr['times']\n",
    "times_pi    = inputVar_pi['times']\n",
    "\n",
    "lati0 = -40.\n",
    "latsi0= min(range(len(lats)), key = lambda i: abs(lats[i] - lati0))\n",
    "lati1 = -85.\n",
    "latsi1= min(range(len(lats)), key = lambda i: abs(lats[i] - lati1))\n",
    "print('lat index for 40.s; 85.s', latsi0, latsi1)\n",
    "\n",
    "\n",
    "shape_latSO = (latsi0 - latsi1) + 1 \n",
    "#print(shape_latSO)\n",
    "\n",
    "\n",
    "#..abrupt4xCO2 Variables: LWP, tas(gmt), SST, p-e, LTS, subsidence\n",
    "LWP_abr  = array(inputVar_abr['clwvi']) - array(inputVar_abr['clivi'])   #..units in kg m^-2\n",
    "\n",
    "gmt_abr  = array(inputVar_abr['tas'])\n",
    "SST_abr  = array(inputVar_abr['sfc_T'])\n",
    "\n",
    "Precip_abr = array(inputVar_abr['P']) * (24.*60.*60.)   #.. Precipitation. Convert the units from kg m^-2 s^-1 -> mm*day^-1\n",
    "\n",
    "lh_vaporization_abr = (2.501 - (2.361 * 10**-3) * (SST_abr - 273.15)) * 1e6  # the latent heat of vaporization at the surface Temperature\n",
    "# Eva_abr2 = array(inputVar_abr['E']) * (24. * 60 * 60)\n",
    "Eva_abr1 = array(inputVar_abr['E']) / lh_vaporization_abr * (24. * 60 * 60)  #.. Evaporation, mm day^-1\n",
    "\n",
    "MC_abr = Precip_abr - Eva_abr1   #..Moisture Convergence calculated from abrupt4xCO2's P - E, Units in mm day^-1\n",
    "\n",
    "Twp_abr  = array(inputVar_abr['clwvi'])\n",
    "Iwp_abr  = array(inputVar_abr['clivi'])\n",
    "\n",
    "if np.min(LWP_abr)<-1e-5:\n",
    "    LWP_abr = Twp_abr\n",
    "    print('clwvi mislabeled')\n",
    "print('Abr simple global-mean-gmt(K): ', nanmean(gmt_abr))\n",
    "\n",
    "#..pi-Control Variables: LWP, tas(gmt), SST, p-e, LTS, subsidence\n",
    "LWP  = array(inputVar_pi['clwvi']) - array(inputVar_pi['clivi'])  #..units in kg m^-2\n",
    "\n",
    "gmt  = array(inputVar_pi['tas'])\n",
    "SST  = array(inputVar_pi['sfc_T'])\n",
    "\n",
    "Precip = array(inputVar_pi['P'])* (24.*60.*60.)    #..Precipitation. Convert the units from kg m^-2 s^-1 -> mm*day^-1\n",
    "\n",
    "lh_vaporization = (2.501 - (2.361 * 10**-3) * (SST - 273.15)) * 1e6  # the latent heat of vaporization at the surface Temperature\n",
    "Eva1 = array(inputVar_pi['E']) / lh_vaporization * (24. * 60 * 60)\n",
    "# Eva2 = array(inputVar_pi['E']) * (24.*60.*60.)   #..evaporation, mm day^-1\n",
    "\n",
    "MC = Precip - Eva1   #..Moisture Convergence calculated from pi-Control's P - E, Units in mm day^-1\n",
    "\n",
    "Twp  = array(inputVar_pi['clwvi'])\n",
    "Iwp  = array(inputVar_pi['clivi'])\n",
    "\n",
    "print('pi-C simple global mean-gmt(K): ', nanmean(gmt))\n",
    "if np.min(LWP)<-1e-5:\n",
    "    LWP = Twp\n",
    "    print('clwvi mislabeled')\n",
    "\n",
    "#..abrupt4xCO2\n",
    "# Lower Tropospheric Stability:\n",
    "k  = 0.286\n",
    "theta_700_abr = array(inputVar_abr['T_700']) * (100000./70000.)** k\n",
    "theta_skin_abr = array(inputVar_abr['sfc_T']) * (100000./ array(inputVar_abr['sfc_P'])) **k\n",
    "LTS_m_abr = theta_700_abr - theta_skin_abr\n",
    "\n",
    "#..Subtract the outliers in T_700 and LTS_m, 'nan' comes from missing T_700 data\n",
    "LTS_e_abr = ma.masked_where(theta_700_abr >= 500, LTS_m_abr)\n",
    "\n",
    "\n",
    "# Meteorology Subsidence at 500 hPa, units in Pa s^-1:\n",
    "Subsidence_abr = array(inputVar_abr['sub'])\n",
    "\n",
    "\n",
    "#..pi-Control \n",
    "# Lower Tropospheric Stability:\n",
    "theta_700  = array(inputVar_pi['T_700']) * (100000./70000.)** k\n",
    "theta_skin = array(inputVar_pi['sfc_T']) * (100000./ array(inputVar_pi['sfc_P'])) **k\n",
    "LTS_m = theta_700 - theta_skin\n",
    "\n",
    "#..Subtract the outliers in T_700 and LTS_m \n",
    "LTS_e = ma.masked_where(theta_700 >= 500, LTS_m)\n",
    "\n",
    "\n",
    "#..Meteological Subsidence at 500 hPa, units in Pa s^-1:\n",
    "Subsidence = array(inputVar_pi['sub'])\n",
    "\n",
    "\n",
    "# define Dictionary to store: CCFs(4), gmt, other variables:\n",
    "dict0_PI_var = {'gmt': gmt, 'LWP': LWP, 'TWP': Twp, 'IWP': Iwp, 'SST': SST, 'p_e': MC, 'LTS': LTS_e, 'SUB': Subsidence\n",
    "                 ,'lat':lats, 'lon':lons, 'times': times_pi, 'pres':levels}\n",
    "\n",
    "dict0_abr_var = {'gmt': gmt_abr, 'LWP': LWP_abr, 'TWP': Twp_abr, 'IWP': Iwp_abr, 'SST': SST_abr, 'p_e': MC_abr, 'LTS': LTS_e_abr \n",
    "                 ,'SUB': Subsidence_abr, 'lat':lats, 'lon':lons, 'times': times_abr, 'pres':levels}\n",
    "\n",
    "\n",
    "\n",
    "# get the Annual-mean, Southern-Ocean region arrays\n",
    "\n",
    "datavar_nas = ['LWP', 'TWP', 'IWP', 'SST', 'p_e', 'LTS', 'SUB']   #..7 varisables except gmt (lon dimension diff)\n",
    "\n",
    "dict1_PI_yr  = {}\n",
    "dict1_abr_yr = {}\n",
    "\n",
    "shape_yr_pi  = shape_time_pi//12\n",
    "shape_yr_abr =  shape_time_abr//12\n",
    "\n",
    "\n",
    "layover_yr_abr = zeros((len(datavar_nas), shape_yr_abr, shape_latSO, shape_lon))\n",
    "layover_yr_pi = zeros((len(datavar_nas), shape_yr_pi, shape_latSO, shape_lon))\n",
    "\n",
    "layover_yr_abr_gmt = zeros((shape_yr_abr, shape_lat, shape_lon))\n",
    "layover_yr_pi_gmt = zeros((shape_yr_pi, shape_lat, shape_lon))\n",
    "\n",
    "\n",
    "for a in range(len(datavar_nas)):\n",
    "\n",
    "    for i in range(shape_time_abr//12):\n",
    "        layover_yr_abr[a, i,:,:] =  nanmean(dict0_abr_var[datavar_nas[a]][i*12:(i+1)*12, latsi1:latsi0+1,:], axis=0)\n",
    "\n",
    "    dict1_abr_yr[datavar_nas[a]+'_yr'] =  layover_yr_abr[a,:]\n",
    "\n",
    "    for j in range(shape_time_pi//12):\n",
    "        layover_yr_pi[a, j,:,:]  = nanmean(dict0_PI_var[datavar_nas[a]][j*12:(j+1)*12,  latsi1:latsi0+1,:], axis=0)\n",
    "\n",
    "    dict1_PI_yr[datavar_nas[a]+'_yr'] =  layover_yr_pi[a,:]\n",
    "\n",
    "    print(datavar_nas[a], \" finish calculating annually-mean array\")   \n",
    "\n",
    "\n",
    "\n",
    "for i in range(shape_time_abr//12):\n",
    "\n",
    "    layover_yr_abr_gmt[i,:,:]  =  nanmean(dict0_abr_var['gmt'][i*12:(i+1)*12, :,:], axis=0)\n",
    "dict1_abr_yr['gmt_yr']  =   layover_yr_abr_gmt\n",
    "\n",
    "\n",
    "for j in range(shape_time_pi//12):\n",
    "    layover_yr_pi_gmt[j,:,:]  =   nanmean(dict0_PI_var['gmt'][j*12:(j+1)*12, :,:], axis=0)\n",
    "dict1_PI_yr['gmt_yr']  =   layover_yr_pi_gmt\n",
    "\n",
    "print('gmt', \" finsih calc annuallt mean gmt\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate 5*5 bin array for variables (LWP, CCFs) in Southern Ocean Region:\n",
    "\n",
    "#..set area-mean range and define function\n",
    "x_range  = arange(-180., 180., 5.) #..logitude sequences edge: number: 72\n",
    "s_range  = arange(-90., 90, 5.)+ 2.5 #..global-region latitude edge: (36)\n",
    "y_range  = arange(-85, -40., 5.) +2.5 #..southern-ocaen latitude edge: 9\n",
    "\n",
    "\n",
    "# Annually variables in bin box: \n",
    "lat_array  = lats[latsi1:latsi0+1]\n",
    "lon_array  = lons\n",
    "lat_array1 =  lats\n",
    "#..big storage dict\n",
    "dict1_PI_var   = {}\n",
    "dict1_abr_var  =  {}\n",
    "dict1_yr_bin_PI  = {}\n",
    "dict1_yr_bin_abr = {}\n",
    "\n",
    "\n",
    "for b in range(len(datavar_nas)):\n",
    "\n",
    "    dict1_yr_bin_abr[datavar_nas[b]+'_yr_bin'] = binned_cySouthOcean5(dict1_abr_yr[datavar_nas[b]+'_yr'], lat_array, lon_array)\n",
    "    dict1_yr_bin_PI[datavar_nas[b]+'_yr_bin'] = binned_cySouthOcean5(dict1_PI_yr[datavar_nas[b]+'_yr'], lat_array, lon_array)\n",
    "    print(datavar_nas[b], \" finished calculating annually-mean bin array\") \n",
    "\n",
    "dict1_yr_bin_abr['gmt_yr_bin'] = binned_cyGlobal5(dict1_abr_yr['gmt_yr'], lat_array1, lon_array)\n",
    "dict1_yr_bin_PI['gmt_yr_bin'] = binned_cyGlobal5(dict1_PI_yr['gmt_yr'], lat_array1, lon_array)\n",
    "\n",
    "print('gmt_yr_bin', \" finish calc annually-mean binned gmt\")\n",
    "\n",
    "dict1_abr_var['dict1_yr_bin_abr'] = dict1_yr_bin_abr\n",
    "dict1_PI_var['dict1_yr_bin_PI'] = dict1_yr_bin_PI\n",
    "\n",
    "\n",
    "\n",
    "# Monthly variables (same as above):\n",
    "dict1_mon_bin_PI  = {}\n",
    "dict1_mon_bin_abr = {}\n",
    "\n",
    "for c in range(len(datavar_nas)):\n",
    "\n",
    "    dict1_mon_bin_abr[datavar_nas[c]+'_mon_bin'] =  binned_cySouthOcean5(dict0_abr_var[datavar_nas[c]][:, latsi1:latsi0+1,:], lat_array, lon_array)\n",
    "    dict1_mon_bin_PI[datavar_nas[c]+'_mon_bin'] = binned_cySouthOcean5(dict0_PI_var[datavar_nas[c]][:, latsi1:latsi0+1,:], lat_array, lon_array)\n",
    "    print(datavar_nas[c], \" finish calculating monthly-mean bin array\")\n",
    "\n",
    "dict1_mon_bin_abr['gmt_mon_bin'] = binned_cyGlobal5(dict0_abr_var['gmt'], lat_array1, lon_array)\n",
    "dict1_mon_bin_PI['gmt_mon_bin'] = binned_cyGlobal5(dict0_PI_var['gmt'], lat_array1, lon_array)\n",
    "\n",
    "print('gmt_mon_bin', \" finish calc monthly-mean binned gmt\")\n",
    "\n",
    "dict1_abr_var['dict1_mon_bin_abr'] = dict1_mon_bin_abr\n",
    "dict1_PI_var['dict1_mon_bin_PI'] = dict1_mon_bin_PI\n",
    "\n",
    "\n",
    "# input the shapes of year and month of pi&abr exper into the raw data dictionaries:\n",
    "dict1_abr_var['shape_yr'] = shape_yr_abr\n",
    "dict1_PI_var['shape_yr'] = shape_yr_pi\n",
    "dict1_abr_var['shape_mon'] = shape_time_abr\n",
    "dict1_PI_var['shape_mon'] = shape_time_pi\n",
    "\n",
    "\n",
    "\n",
    "# Output a dict for processing function in 'calc_LRM_metrics', stored the data dicts for PI and abr, with the model name_dict\n",
    "# C_dict =  {'dict0_PI_var':dict1_PI_var, 'dict0_abr_var':dict1_abr_var, 'model_data':model_data}    #..revised in Dec.30th, at 2021,, note the name.\n",
    "\n",
    "\n",
    "# Second step processing data\n",
    "\n",
    "# load annually-mean bin data\n",
    "dict1_yr_bin_PI  = dict1_PI_var['dict1_yr_bin_PI']\n",
    "dict1_yr_bin_abr  = dict1_abr_var['dict1_yr_bin_abr']\n",
    "\n",
    "\n",
    "# load monthly bin data\n",
    "dict1_mon_bin_PI  = dict1_PI_var['dict1_mon_bin_PI']\n",
    "dict1_mon_bin_abr  = dict1_abr_var['dict1_mon_bin_abr']\n",
    "\n",
    "# data array in which shapes?\n",
    "shape_yr_PI_3 = dict1_yr_bin_PI['LWP_yr_bin'].shape\n",
    "shape_yr_abr_3 = dict1_yr_bin_abr['LWP_yr_bin'].shape\n",
    "\n",
    "shape_yr_PI_gmt = dict1_yr_bin_PI['gmt_yr_bin'].shape\n",
    "shape_yr_abr_gmt = dict1_yr_bin_abr['gmt_yr_bin'].shape\n",
    "\n",
    "shape_mon_PI_3 = dict1_mon_bin_PI['LWP_mon_bin'].shape\n",
    "shape_mon_abr_3 = dict1_mon_bin_abr['LWP_mon_bin'].shape\n",
    "\n",
    "shape_mon_PI_gmt = dict1_mon_bin_PI['gmt_mon_bin'].shape\n",
    "shape_mon_abr_gmt = dict1_mon_bin_abr['gmt_mon_bin'].shape\n",
    "\n",
    "# flatten the data array for 'training' lrm  coefficience\n",
    "\n",
    "dict2_predi_fla_PI = {}\n",
    "dict2_predi_fla_abr = {}\n",
    "\n",
    "dict2_predi_ano_PI = {}  # need a climatological arrays of variables\n",
    "dict2_predi_ano_abr = {}  # need a climatological arrays of variables\n",
    "\n",
    "dict2_predi_nor_PI = {}  # standardized anomalies of variables\n",
    "dict2_predi_nor_abr = {}\n",
    "\n",
    "dict2_predi = {}\n",
    "\n",
    "#..Ravel binned array /Standardized data ARRAY :\n",
    "for d in range(len(datavar_nas)):\n",
    "\n",
    "    dict2_predi_fla_PI[datavar_nas[d]] = dict1_mon_bin_PI[datavar_nas[d]+'_mon_bin'].flatten()\n",
    "    dict2_predi_fla_abr[datavar_nas[d]] = dict1_mon_bin_abr[datavar_nas[d]+'_mon_bin'].flatten()\n",
    "\n",
    "    # anomalies in the raw units:\n",
    "    # 'dict2_predi' as a dict for reference-period (mean state) data\n",
    "    dict2_predi[datavar_nas[d]] = deepcopy(dict1_mon_bin_PI[datavar_nas[d]+'_mon_bin'])\n",
    "\n",
    "    dict2_predi_ano_PI[datavar_nas[d]] = dict2_predi_fla_PI[datavar_nas[d]] - nanmean(area_mean(dict2_predi[datavar_nas[d]], y_range, x_range))\n",
    "    dict2_predi_ano_abr[datavar_nas[d]] = dict2_predi_fla_abr[datavar_nas[d]] - nanmean(area_mean(dict2_predi[datavar_nas[d]], y_range,x_range))\n",
    "\n",
    "    # normalized stardard deviation in unit of './std':\n",
    "    dict2_predi_nor_PI[datavar_nas[d]] = dict2_predi_ano_PI[datavar_nas[d]] / nanstd(dict2_predi_fla_PI[datavar_nas[d]])  # divided by monthly standard variance\n",
    "    dict2_predi_nor_abr[datavar_nas[d]] = dict2_predi_ano_abr[datavar_nas[d]] / nanstd(dict2_predi_fla_PI[datavar_nas[d]])\n",
    "\n",
    "#.. global-mean surface air temperature\n",
    "# shape of 'GMT' is the length of time (t)\n",
    "dict2_predi_fla_PI['gmt'] = area_mean(dict1_mon_bin_PI['gmt_mon_bin'], s_range, x_range)\n",
    "dict2_predi_fla_abr['gmt'] = area_mean(dict1_mon_bin_abr['gmt_mon_bin'], s_range, x_range)\n",
    "\n",
    "dict2_predi['gmt'] = deepcopy(dict2_predi_fla_PI['gmt'])\n",
    "shape_whole_period = asarray(dict2_predi['gmt'].shape[0])\n",
    "\n",
    "dict2_predi_ano_abr['gmt'] = dict2_predi_fla_abr['gmt'] - np.nanmean(dict2_predi['gmt'])  # shape in (t, lat, lon).flatten()\n",
    "dict2_predi_ano_PI['gmt'] = dict2_predi_fla_PI['gmt'] - np.nanmean(dict2_predi['gmt'])  # shape in (t, lat, lon).flatten()\n",
    "\n",
    "dict2_predi_nor_abr['gmt'] = dict2_predi_ano_abr['gmt'] / np.nanstd(dict2_predi_fla_PI['gmt'])\n",
    "dict2_predi_nor_PI['gmt'] = dict2_predi_ano_PI['gmt'] / np.nanstd(dict2_predi_fla_PI['gmt'])\n",
    "\n",
    "# shape of flattened array:\n",
    "metric_training = deepcopy(dict2_predi_ano_PI)\n",
    "metric_predict = deepcopy(dict2_predi_ano_abr)\n",
    "\n",
    "shape_fla_PI = dict2_predi_fla_PI['LWP'].shape\n",
    "shape_fla_abr = dict2_predi_fla_abr['LWP'].shape\n",
    "\n",
    "# For pluging in different sets of cut-off(TR_sst & TR_sub) into LRM(s):\n",
    "# split cut-off: TR_sst and TR_sub for N1 and N2 slices in sort of self-defined (Mon)variable ranges\n",
    "\n",
    "YY_ay_gcm = metric_training['SST']\n",
    "XX_ay_gcm = metric_training['SUB']\n",
    "\n",
    "y_gcm = linspace(nanpercentile(YY_ay_gcm, 2), nanpercentile(YY_ay_gcm, 99), 31)   #..supposed to be changed, 31\n",
    "x_gcm = linspace(nanpercentile(XX_ay_gcm, 5), nanpercentile(XX_ay_gcm, 95), 22)   #.., 22\n",
    "\n",
    "print(\"slice SUB bound:  \", x_gcm)\n",
    "print(\"slice SST bound:  \", y_gcm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58348b1-9419-4163-8e5d-dff87cf9ecb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
